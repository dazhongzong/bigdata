import pyodbc
import pandas as pd
import numpy as np
import json
import logging
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import os
import argparse
class ExcelToSQLImporter:
    """ExcelÊï∞ÊçÆÂØºÂÖ•SQL ServerÁöÑÂ∑•ÂÖ∑Á±ªÔºàÊîØÊåÅJSONÈÖçÁΩÆÔºâ"""
    
    def __init__(self, config: Dict):
        """
        ‰ªéÈÖçÁΩÆÂ≠óÂÖ∏ÂàùÂßãÂåñÂèÇÊï∞
        
        :param config: ÂåÖÂê´Êï∞ÊçÆÂ∫ìËøûÊé•ÂíåÂØºÂÖ•ËÆæÁΩÆÁöÑÂ≠óÂÖ∏
        """
        # Êï∞ÊçÆÂ∫ìËøûÊé•ÂèÇÊï∞
        sql_config = config["sql_server"]
        self.server = sql_config["server"]
        self.database = sql_config["database"]
        self.username = sql_config["username"]
        self.password = sql_config["password"]
        self.port = sql_config.get("port", 1433)  # ÈªòËÆ§‰∏∫1433
        
        # ÂØºÂÖ•ËÆæÁΩÆ
        import_config = config["import_settings"]
        self.chunk_size = import_config.get("chunk_size", 1000)
        self.if_exists = import_config.get("if_exists", "fail")
        # self.primary_key = import_config.get("primary_key")
        
        # ÂàùÂßãÂåñËøûÊé•ÂíåÊ∏∏Ê†á
        self.conn = None
        self.cursor = None
        
        # ÈÖçÁΩÆÊó•Âøó
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

    def _get_connection_string(self) -> str:
        """ÁîüÊàêSQL ServerËøûÊé•Â≠óÁ¨¶‰∏≤"""
        return (
            f"DRIVER={{ODBC Driver 17 for SQL Server}};"
            f"SERVER={self.server},{self.port};"
            f"DATABASE={self.database};"
            f"UID={self.username};"
            f"PWD={self.password};"
            f"Encrypt=yes;"
            f"TrustServerCertificate=yes"
        )

    def connect(self) -> None:
        try:
            self.conn = pyodbc.connect(self._get_connection_string())
            self.cursor = self.conn.cursor()
            self.cursor.fast_executemany = True  # üî• Ê†∏ÂøÉÊèêÈÄüÂºÄÂÖ≥
            self.logger.info(f"ÊàêÂäüËøûÊé•Âà∞ {self.server}/{self.database}")
        except pyodbc.Error as e:
            self.logger.error(f"ËøûÊé•Â§±Ë¥•: {str(e)}")
            raise

    def close(self) -> None:
        """ÂÖ≥Èó≠Êï∞ÊçÆÂ∫ìËøûÊé•"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.close()
            self.logger.info("Êï∞ÊçÆÂ∫ìËøûÊé•Â∑≤ÂÖ≥Èó≠")

    def _map_data_type(self, pandas_dtype) -> str:
        """Êò†Â∞ÑpandasÊï∞ÊçÆÁ±ªÂûãÂà∞SQL ServerÁ±ªÂûã"""
        if pd.api.types.is_integer_dtype(pandas_dtype):
            return "INT"
        elif pd.api.types.is_float_dtype(pandas_dtype):
            return "DECIMAL(18, 4)"
        elif pd.api.types.is_datetime64_any_dtype(pandas_dtype):
            return "DATETIME"
        elif pd.api.types.is_bool_dtype(pandas_dtype):
            return "BIT"
        else:
            return "NVARCHAR(255)"

    def _create_table_sql(self, table_name: str, df: pd.DataFrame) -> str:
        """ÁîüÊàêÂàõÂª∫Ë°®ÁöÑSQLËØ≠Âè•"""
        columns = []
        for col in df.columns:
            sql_col = col
            sql_type = self._map_data_type(df[col].dtype)
            columns.append(f"[{sql_col}] {sql_type}")
        
        # ‰∏ªÈîÆÁ∫¶Êùü
        #primary_key_sql = f", PRIMARY KEY ({self.primary_key})" if self.primary_key else ""
        
        return f"""
        CREATE TABLE [{table_name}] (
            {', '.join(columns)}
        )
        """.strip()

    def _prepare_data(self, df: pd.DataFrame) -> List[Tuple]:
        """È¢ÑÂ§ÑÁêÜÊï∞ÊçÆÔºàÂ§ÑÁêÜÁ©∫ÂÄºÂíåÊó•ÊúüÊ†ºÂºèÔºâ"""
        df = df.replace({np.nan: None})
        
        # ËΩ¨Êç¢Êó•ÊúüÊ†ºÂºè
        for col in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[col].dtype):
                df[col] = df[col].apply(
                    lambda x: x.strftime("%Y-%m-%d %H:%M:%S") if pd.notnull(x) else None
                )
        
        return [tuple(row) for row in df.itertuples(index=False, name=None)]

    def import_excel(self, excel_path: str, table_name: str, sheet_name: str = 0) -> None:
        """ÂØºÂÖ•ExcelÊï∞ÊçÆÂà∞SQL Server"""
        try:
            # ËØªÂèñExcel
            self.logger.info(f"ËØªÂèñExcel: {excel_path} (Â∑•‰ΩúË°®: {sheet_name})")
            df = pd.read_excel(excel_path, sheet_name=sheet_name)
            self.logger.info(f"ËØªÂèñÂÆåÊàêÔºåÂÖ± {len(df)} Ë°å")

            # Â§ÑÁêÜÂàóÂêç
            df.columns = [col for col in df.columns]

            # Ê£ÄÊü•Ë°®ÊòØÂê¶Â≠òÂú®
            self.cursor.execute(
                "SELECT COUNT(*) FROM bigdata.sys.tables WHERE name = ?", (table_name,)
            )
            table_exists = self.cursor.fetchone()[0] == 1

            # Â§ÑÁêÜË°®Â≠òÂú®ÁöÑÊÉÖÂÜµ
            if table_exists:
                if self.if_exists == "fail":
                    self.logger.error(f"Ë°® {table_name} Â∑≤Â≠òÂú®ÔºåÁªàÊ≠¢ÂØºÂÖ•")
                    return
                elif self.if_exists == "replace":
                    self.logger.info(f"Ê∏ÖÁ©∫Ë°® {table_name}")
                    self.cursor.execute(f"TRUNCATE TABLE [{table_name}]")
                    self.conn.commit()
                elif self.if_exists == "append":
                    self.logger.info(f"Ë°® {table_name} Â∑≤Â≠òÂú®ÔºåËøΩÂä†Êï∞ÊçÆ")
                elif self.if_exists == "delete":
                    self.logger.info(f"Âà†Èô§Ë°® {table_name}")
                    self.cursor.execute(f"DROP TABLE [{table_name}]")
                    # ÂàõÂª∫Êñ∞Ë°®
                    self.logger.info(f"ÂàõÂª∫Ë°® {table_name}")
                    self.cursor.execute(self._create_table_sql(table_name, df))
                    self.conn.commit()
                else:
                    raise ValueError(f"Êú™Áü•ÁöÑ if_exists ÂèÇÊï∞: {self.if_exists}")
            else:
                # ÂàõÂª∫Êñ∞Ë°®
                self.logger.info(f"ÂàõÂª∫Ë°® {table_name}")
                self.cursor.execute(self._create_table_sql(table_name, df))
                self.conn.commit()

            # Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ
            data = self._prepare_data(df)
            if not data:
                self.logger.warning("Êó†Êï∞ÊçÆÂèØÂØºÂÖ•")
                return

            # ÊâπÈáèÊèíÂÖ•
            self.logger.info(f"ÂºÄÂßãÂØºÂÖ•ÔºåÊâπÊ¨°Â§ßÂ∞è: {self.chunk_size}")
            columns = ", ".join([f"[{col}]" for col in df.columns])
            placeholders = ", ".join(["?" for _ in df.columns])
            
            insert_sql = f"INSERT INTO [{table_name}] ({columns}) VALUES ({placeholders})"

            # ÂàÜÊâπÊ¨°ÊâßË°å
            total = len(data)
            for i in range(0, total, self.chunk_size):
                chunk = data[i:i+self.chunk_size]
                self.cursor.executemany(insert_sql, chunk)
                self.conn.commit()
                self.logger.info(f"ËøõÂ∫¶: {min(i+self.chunk_size, total)}/{total} Ë°å")

            self.logger.info(f"ÂØºÂÖ•ÊàêÂäüÔºåÂÖ± {total} Ë°å")

        except Exception as e:
            self.conn.rollback()
            self.logger.error(f"ÂØºÂÖ•Â§±Ë¥•: {str(e)}")
            raise

def load_config(config_path: str = "./config.json") -> Dict:
    """
    ‰ªéJSONÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ
    
    :param config_path: JSONÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ
    :return: ÈÖçÁΩÆÂ≠óÂÖ∏
    """
    
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"ÈÖçÁΩÆÊñá‰ª∂ {config_path} ‰∏çÂ≠òÂú®")
    except json.JSONDecodeError:
        raise ValueError(f"ÈÖçÁΩÆÊñá‰ª∂ {config_path} Ê†ºÂºèÈîôËØØ")


def validate_excel(file_path: str) -> bool:
    """È™åËØÅExcelÊñá‰ª∂ÊúâÊïàÊÄß"""
    try:
        pd.read_excel(file_path, nrows=1)
        return True
    except Exception as e:
        logging.error(f"ExcelÈ™åËØÅÂ§±Ë¥•: {str(e)}")
        return False
def load_table(config,excel_path:str,table_name=None,sheet_name=0) -> None:
    # 3. ÊâßË°åÂØºÂÖ•
    if validate_excel(excel_path):
        importer = ExcelToSQLImporter(config)
        try:
            importer.connect()
            importer.import_excel(
                excel_path=excel_path,
                table_name=table_name,
                sheet_name=sheet_name
            )
        finally:
            importer.close()
def load_Fact_Table(config,excel_path:str,table_name=None) -> None:
    
    # 2. ÈÖçÁΩÆÂØºÂÖ•ÂèÇÊï∞
    if table_name is None:
        table_name = os.path.basename(excel_path)
    sheet_name = 0  # Á¨¨‰∏Ä‰∏™Â∑•‰ΩúË°®
    
    load_table(config,excel_path=excel_path,table_name=table_name,sheet_name=sheet_name)
def load_Dim_Table(config,excel_path:str) -> None:
    if os.path.isdir(excel_path):
        files = []
        for file in os.listdir(excel_path):
            if file.endswith(".xlsx"):
                file = os.path.join(excel_path, file)
                files.append(file)
    sheet_name = 0 
    for file in files:
        # 3. ÊâßË°åÂØºÂÖ•
        table_name = os.path.basename(file).split(".")[0]
        load_table(config,excel_path=file,table_name=table_name,sheet_name=sheet_name)

if __name__ == "__main__":

    # 1. Âä†ËΩΩÈÖçÁΩÆ
    config = load_config()
    tables_config = config["tables"]
    if tables_config.get("dim_table",True):
        load_Dim_Table(config,excel_path="./data/dim")
    if tables_config.get("fact_table",True):
        load_Fact_Table(config,excel_path="./output/output.xlsx",table_name="Fact_FlightTicket")